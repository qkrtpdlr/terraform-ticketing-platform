# 🎫 Terraform을 이용한 고가용성 티켓팅 프로젝트 - 완전 실행 가이드

> **작성자**: qkrtpdlr
> **프로젝트**: 고가용성 티켓팅 플랫폼 (Terraform + Spring Boot + AWS)  
> **목표**: AWS에서 처음부터 끝까지 프로젝트를 성공적으로 배포

---

## 📋 목차

1. [프로젝트 개요](#1-프로젝트-개요)
2. [사전 준비사항](#2-사전-준비사항)
3. [전체 실행 순서도](#3-전체-실행-순서도)
4. [단계별 상세 가이드](#4-단계별-상세-가이드)
5. [테스트 및 검증](#5-테스트-및-검증)
6. [모니터링 설정](#6-모니터링-설정)
7. [문제 해결 (Troubleshooting)](#7-문제-해결)
8. [프로젝트 삭제](#8-프로젝트-삭제)

---

## 1. 프로젝트 개요

### 1.1 아키텍처 구성
```
┌─────────────────────────────────────────────────────────┐
│                    Internet Gateway                     │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│              Application Load Balancer                  │
│              (고가용성 로드 밸런싱)                      │
└──────────┬─────────────────────────┬────────────────────┘
           │                         │
    ┌──────▼──────┐           ┌─────▼───────┐
    │   AZ-2a     │           │    AZ-2c    │
    │ Auto Scaling│           │Auto Scaling │
    │  (2-20대)   │           │  (2-20대)   │
    └──────┬──────┘           └─────┬───────┘
           │                         │
           └────────┬─────────┬──────┘
                    │         │
         ┌──────────▼─┐   ┌──▼──────────┐
         │RDS Aurora  │   │ElastiCache  │
         │(Writer+R/R)│   │   Redis     │
         │  Multi-AZ  │   │  Cluster    │
         └────────────┘   └─────────────┘
```

### 1.2 핵심 기능
- ✅ **고가용성**: Multi-AZ 구성으로 99.9% 가용성 보장
- ✅ **자동 확장**: 트래픽에 따라 2~20대 자동 스케일링
- ✅ **동시성 제어**: Redis 분산 락으로 티켓 중복 예매 방지
- ✅ **캐싱**: Redis 캐시로 DB 부하 90% 감소
- ✅ **모니터링**: CloudWatch + SNS 알람으로 실시간 감시

### 1.3 예상 비용
- **Dev 환경**: 월 약 $365
- **Production**: 월 약 $1,200~$2,500 (트래픽에 따라 변동)

---

## 2. 사전 준비사항

### 2.1 필수 소프트웨어 설치

#### ✅ AWS CLI 설치 및 설정
```bash
# macOS
brew install awscli

# Windows (PowerShell)
msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi

# Linux
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# 설치 확인
aws --version
# 출력 예시: aws-cli/2.13.0 Python/3.11.4
```

#### ✅ AWS 자격 증명 설정
```bash
aws configure
# AWS Access Key ID [None]: AKIA************
# AWS Secret Access Key [None]: ****************************
# Default region name [None]: ap-northeast-2
# Default output format [None]: json

# 설정 확인
aws sts get-caller-identity
```

#### ✅ Terraform 설치
```bash
# macOS
brew tap hashicorp/tap
brew install hashicorp/tap/terraform

# Windows (Chocolatey)
choco install terraform

# Linux
wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform

# 설치 확인
terraform --version
# 출력 예시: Terraform v1.6.0
```

#### ✅ Docker 설치
```bash
# macOS
brew install --cask docker

# Windows: Docker Desktop 다운로드
# https://www.docker.com/products/docker-desktop

# Linux (Ubuntu)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# 설치 확인
docker --version
docker-compose --version
```

#### ✅ Git 설치
```bash
# macOS
brew install git

# Windows
winget install --id Git.Git -e --source winget

# Linux
sudo apt install git

# 설치 확인
git --version
```

#### ✅ Java JDK 17 설치 (애플리케이션 빌드용)
```bash
# macOS
brew install openjdk@17

# Linux
sudo apt install openjdk-17-jdk

# Windows: Oracle JDK 다운로드
# https://www.oracle.com/java/technologies/downloads/#java17

# 설치 확인
java -version
# 출력 예시: openjdk version "17.0.8"
```

#### ✅ Maven 설치 (선택사항 - Docker 빌드 시 자동 설치)
```bash
# macOS
brew install maven

# Linux
sudo apt install maven

# 설치 확인
mvn -version
```

### 2.2 AWS 계정 준비사항

#### ✅ 필수 권한 확인
다음 AWS 서비스에 대한 권한이 필요합니다:
- ✅ VPC (네트워크 생성)
- ✅ EC2 (인스턴스, 보안 그룹)
- ✅ RDS (Aurora MySQL)
- ✅ ElastiCache (Redis)
- ✅ ELB (Application Load Balancer)
- ✅ Auto Scaling
- ✅ S3 (백업 스토리지)
- ✅ SQS & SNS (메시징)
- ✅ CloudWatch (모니터링)
- ✅ ECR (Docker 이미지 저장소)
- ✅ IAM (역할 및 정책)

#### ✅ 서비스 한도 확인
```bash
# EC2 인스턴스 한도 확인
aws service-quotas get-service-quota \
  --service-code ec2 \
  --quota-code L-1216C47A

# 한도가 부족하면 AWS Console에서 증가 요청
# AWS Console > Service Quotas > EC2 > Running On-Demand Instances
```

#### ✅ 키 페어 생성
```bash
# EC2 키 페어 생성 (선택사항 - Terraform이 자동 생성 가능)
aws ec2 create-key-pair \
  --key-name ticketing-keypair \
  --query 'KeyMaterial' \
  --output text > ~/.ssh/ticketing-keypair.pem

chmod 400 ~/.ssh/ticketing-keypair.pem
```

### 2.3 프로젝트 파일 준비

#### ✅ AI Drive에서 파일 다운로드
```bash
# 작업 디렉토리 생성
mkdir -p ~/projects/ticketing-platform
cd ~/projects/ticketing-platform

# AI Drive에서 압축 파일 다운로드
# 경로: /Terraform을 이용한 고가용성 티켓팅 프로젝트/
# - terraform-ticketing-platform.tar.gz
# - ticketing-app.tar.gz

# 압축 해제
tar -xzf terraform-ticketing-platform.tar.gz
tar -xzf ticketing-app.tar.gz

# 디렉토리 구조 확인
ls -la
# terraform-ticketing/
# ticketing-app/
```

---

## 3. 전체 실행 순서도

```
┌─────────────────────────────────────────────────────────┐
│              프로젝트 실행 순서 (총 소요시간: 약 40분)   │
└─────────────────────────────────────────────────────────┘

1️⃣ 환경 설정 (5분)
   └─> AWS CLI 인증, Terraform 초기화

2️⃣ Terraform 인프라 배포 (15-20분)
   └─> VPC → Security Groups → RDS → Redis → ALB → Auto Scaling

3️⃣ Spring Boot 애플리케이션 빌드 (5분)
   └─> Maven 빌드 → Docker 이미지 생성

4️⃣ ECR에 이미지 푸시 (3분)
   └─> Docker 이미지를 AWS ECR에 업로드

5️⃣ EC2 인스턴스에 배포 (7분)
   └─> User Data 스크립트로 자동 배포

6️⃣ 테스트 및 검증 (5분)
   └─> API 엔드포인트 테스트, 동시성 테스트

7️⃣ 모니터링 설정 확인 (3분)
   └─> CloudWatch 대시보드, SNS 알람

8️⃣ (선택) 부하 테스트 (10분)
   └─> Locust로 성능 검증

9️⃣ 프로젝트 삭제 (선택, 5분)
   └─> terraform destroy로 모든 리소스 제거
```

---

## 4. 단계별 상세 가이드

### 4.1 STEP 1: 환경 설정 (5분)

#### 1-1. Terraform 프로젝트 초기화
```bash
cd terraform-ticketing

# Terraform 변수 파일 생성
cp terraform.tfvars.example terraform.tfvars

# 변수 파일 편집 (필수)
nano terraform.tfvars
# 또는
vim terraform.tfvars
```

#### 1-2. terraform.tfvars 설정
```hcl
# terraform.tfvars
project_name = "ticketing"
environment  = "dev"
region       = "ap-northeast-2"

# VPC CIDR
vpc_cidr = "10.0.0.0/16"

# 데이터베이스 설정
db_master_username = "admin"
db_master_password = "YourSecurePassword123!"  # 강력한 비밀번호로 변경!

# Auto Scaling 설정
min_size     = 2
max_size     = 20
desired_size = 2

# 알람 이메일 (본인 이메일로 변경)
alarm_email = "your-email@example.com"

# 태그
tags = {
  Project     = "Ticketing Platform"
  Owner       = "박세익"
  Environment = "Development"
  ManagedBy   = "Terraform"
}
```

#### 1-3. Terraform 초기화
```bash
# Provider 플러그인 다운로드
terraform init

# 출력 예시:
# Initializing the backend...
# Initializing provider plugins...
# - Finding hashicorp/aws versions matching "~> 5.0"...
# Terraform has been successfully initialized!

# 문법 검증
terraform validate

# 출력 예시:
# Success! The configuration is valid.

# 포맷팅 (선택)
terraform fmt -recursive
```

---

### 4.2 STEP 2: Terraform 인프라 배포 (15-20분)

#### 2-1. 배포 계획 확인
```bash
# 어떤 리소스가 생성될지 미리보기
terraform plan

# 출력 예시:
# Plan: 45 to add, 0 to change, 0 to destroy.
#
# Changes to Outputs:
#   + alb_dns_name     = (known after apply)
#   + db_endpoint      = (known after apply)
#   + redis_endpoint   = (known after apply)
```

#### 2-2. 인프라 배포 실행
```bash
# 방법 1: 스크립트 사용 (권장)
chmod +x scripts/deploy.sh
./scripts/deploy.sh

# 방법 2: 수동 실행
terraform apply

# 확인 메시지에서 "yes" 입력
# Do you want to perform these actions? yes

# 배포 진행 중... (약 15-20분 소요)
# ⏱️ 주요 단계별 소요 시간:
# - VPC & Subnets: 2분
# - Security Groups: 1분
# - RDS Aurora: 10-12분 (가장 오래 걸림)
# - ElastiCache Redis: 5-7분
# - ALB: 2분
# - Auto Scaling: 3분
```

#### 2-3. 배포 결과 확인
```bash
# 출력값 확인
terraform output

# 출력 예시:
# alb_dns_name = "ticketing-dev-alb-1234567890.ap-northeast-2.elb.amazonaws.com"
# db_endpoint = "ticketing-dev-aurora-cluster.cluster-xyz.ap-northeast-2.rds.amazonaws.com:3306"
# redis_endpoint = "ticketing-dev-redis.abc123.ng.0001.apse2.cache.amazonaws.com:6379"
# ecr_repository_url = "123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/ticketing-dev"

# 중요한 값들을 별도로 저장
terraform output -raw alb_dns_name > ../alb_dns.txt
terraform output -raw ecr_repository_url > ../ecr_url.txt
terraform output -raw db_endpoint > ../db_endpoint.txt
terraform output -raw redis_endpoint > ../redis_endpoint.txt
```

#### 2-4. AWS Console에서 확인
1. **VPC**: https://console.aws.amazon.com/vpc/
   - VPC, Subnets (Public x2, Private x2, Database x2) 확인
   
2. **RDS**: https://console.aws.amazon.com/rds/
   - Aurora Cluster (Writer + Reader) 상태 확인
   
3. **ElastiCache**: https://console.aws.amazon.com/elasticache/
   - Redis Cluster 상태 확인
   
4. **EC2 Load Balancers**: https://console.aws.amazon.com/ec2/v2/home#LoadBalancers
   - ALB 상태 "active" 확인
   
5. **Auto Scaling Groups**: https://console.aws.amazon.com/ec2autoscaling/
   - Desired: 2, Running: 2 확인

---

### 4.3 STEP 3: Spring Boot 애플리케이션 빌드 (5분)

#### 3-1. 애플리케이션 설정 확인
```bash
cd ../ticketing-app

# application.yml 확인
cat src/main/resources/application.yml
```

#### 3-2. 애플리케이션 설정 업데이트
```yaml
# src/main/resources/application.yml
spring:
  application:
    name: ticketing-service
  
  datasource:
    # Terraform output에서 가져온 RDS 엔드포인트로 변경
    url: jdbc:mysql://ticketing-dev-aurora-cluster.cluster-xyz.ap-northeast-2.rds.amazonaws.com:3306/ticketing?createDatabaseIfNotExist=true
    username: admin
    password: YourSecurePassword123!  # terraform.tfvars와 동일
    driver-class-name: com.mysql.cj.jdbc.Driver
  
  redis:
    # Terraform output에서 가져온 Redis 엔드포인트로 변경
    host: ticketing-dev-redis.abc123.ng.0001.apse2.cache.amazonaws.com
    port: 6379
    timeout: 2000ms
  
  jpa:
    hibernate:
      ddl-auto: update  # 프로덕션에서는 validate로 변경
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
        format_sql: true
    show-sql: true
```

#### 3-3. Docker 이미지 빌드
```bash
# 로컬에서 테스트 (선택사항)
docker-compose up -d

# 테스트 API 호출
curl http://localhost:8080/api/health
# 출력: {"status":"UP","timestamp":"2024-..."}

# 테스트 완료 후 중지
docker-compose down

# 프로덕션용 Docker 이미지 빌드
docker build -t ticketing-app:latest .

# 빌드 확인
docker images | grep ticketing-app
# 출력 예시:
# ticketing-app   latest   1a2b3c4d5e6f   2 minutes ago   300MB
```

---

### 4.4 STEP 4: ECR에 이미지 푸시 (3분)

#### 4-1. ECR 로그인
```bash
# Terraform output에서 ECR URL 가져오기
ECR_URL=$(cat ../ecr_url.txt)
REGION="ap-northeast-2"

# ECR 로그인
aws ecr get-login-password --region $REGION | \
  docker login --username AWS --password-stdin $ECR_URL

# 출력 예시:
# Login Succeeded
```

#### 4-2. Docker 이미지 태깅 및 푸시
```bash
# 이미지 태깅
docker tag ticketing-app:latest $ECR_URL:latest
docker tag ticketing-app:latest $ECR_URL:v1.0.0

# ECR에 푸시
docker push $ECR_URL:latest
docker push $ECR_URL:v1.0.0

# 출력 예시:
# The push refers to repository [123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/ticketing-dev]
# latest: digest: sha256:abc123... size: 2828
# v1.0.0: digest: sha256:abc123... size: 2828
```

#### 4-3. ECR에서 이미지 확인
```bash
# CLI로 확인
aws ecr describe-images \
  --repository-name ticketing-dev \
  --region ap-northeast-2

# AWS Console에서 확인
# https://console.aws.amazon.com/ecr/repositories/ticketing-dev
```

---

### 4.5 STEP 5: EC2 인스턴스에 배포 (7분)

#### 5-1. Auto Scaling Group 인스턴스 확인
```bash
# Auto Scaling Group 이름 가져오기
ASG_NAME="ticketing-dev-asg"

# 실행 중인 인스턴스 확인
aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names $ASG_NAME \
  --query 'AutoScalingGroups[0].Instances[*].[InstanceId,LifecycleState,HealthStatus]' \
  --output table

# 출력 예시:
# --------------------------------
# |  i-0abc123  |  InService  |  Healthy  |
# |  i-0def456  |  InService  |  Healthy  |
# --------------------------------
```

#### 5-2. User Data 스크립트 동작 확인
```bash
# 인스턴스 ID 가져오기
INSTANCE_ID=$(aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names $ASG_NAME \
  --query 'AutoScalingGroups[0].Instances[0].InstanceId' \
  --output text)

# User Data 실행 로그 확인
aws ssm send-command \
  --instance-ids $INSTANCE_ID \
  --document-name "AWS-RunShellScript" \
  --parameters 'commands=["tail -100 /var/log/user-data.log"]' \
  --output text

# 또는 SSH로 접속 (키 페어가 있는 경우)
ssh -i ~/.ssh/ticketing-keypair.pem ec2-user@<INSTANCE_PUBLIC_IP>
sudo tail -f /var/log/user-data.log
```

#### 5-3. 애플리케이션 배포 대기
```bash
# User Data 스크립트가 다음 작업을 자동 수행:
# 1. Docker 설치
# 2. ECR 로그인
# 3. Docker 이미지 Pull
# 4. 애플리케이션 실행 (포트 8080)
# 5. Health Check 대기

# 약 5-7분 소요
echo "애플리케이션 배포 중... (5-7분 소요)"
sleep 420  # 7분 대기
```

---

### 4.6 STEP 6: ALB Target Health 확인

#### 6-1. Target Group 상태 확인
```bash
# Target Group ARN 가져오기
TG_ARN=$(aws elbv2 describe-target-groups \
  --names ticketing-dev-tg \
  --query 'TargetGroups[0].TargetGroupArn' \
  --output text)

# Target Health 확인
aws elbv2 describe-target-health \
  --target-group-arn $TG_ARN \
  --output table

# 출력 예시:
# --------------------------------
# |  TargetId     |  TargetHealth  |
# |  i-0abc123    |  healthy       |
# |  i-0def456    |  healthy       |
# --------------------------------
```

#### 6-2. AWS Console에서 확인
1. **EC2 > Target Groups**: https://console.aws.amazon.com/ec2/v2/home#TargetGroups
2. **ticketing-dev-tg** 클릭
3. **Targets** 탭에서 모든 인스턴스가 "healthy" 상태인지 확인

---

## 5. 테스트 및 검증

### 5.1 API 엔드포인트 테스트

#### 5-1. ALB DNS 주소 가져오기
```bash
ALB_DNS=$(cat ../alb_dns.txt)
echo "ALB DNS: $ALB_DNS"
# 예시: ticketing-dev-alb-1234567890.ap-northeast-2.elb.amazonaws.com
```

#### 5-2. Health Check
```bash
curl http://$ALB_DNS/api/health

# 예상 응답:
# {
#   "status": "UP",
#   "timestamp": "2024-10-27T10:30:00Z",
#   "database": "connected",
#   "redis": "connected"
# }
```

#### 5-3. 이벤트 생성
```bash
curl -X POST http://$ALB_DNS/api/events \
  -H "Content-Type: application/json" \
  -d '{
    "eventName": "IU 콘서트",
    "totalSeats": 10000,
    "eventDate": "2024-12-31T19:00:00"
  }'

# 예상 응답:
# {
#   "success": true,
#   "message": "Event created successfully",
#   "data": {
#     "eventId": 1,
#     "eventName": "IU 콘서트",
#     "totalSeats": 10000,
#     "availableSeats": 10000,
#     "eventDate": "2024-12-31T19:00:00"
#   }
# }
```

#### 5-4. 이벤트 목록 조회
```bash
curl http://$ALB_DNS/api/events

# 예상 응답:
# {
#   "success": true,
#   "data": [
#     {
#       "eventId": 1,
#       "eventName": "IU 콘서트",
#       "availableSeats": 10000,
#       "eventDate": "2024-12-31T19:00:00"
#     }
#   ]
# }
```

#### 5-5. 티켓 예매 (단건)
```bash
curl -X POST http://$ALB_DNS/api/reservations \
  -H "Content-Type: application/json" \
  -d '{
    "eventId": 1,
    "userId": "user123",
    "quantity": 2
  }'

# 예상 응답:
# {
#   "success": true,
#   "message": "Reservation successful",
#   "data": {
#     "reservationId": "550e8400-e29b-41d4-a716-446655440000",
#     "eventId": 1,
#     "userId": "user123",
#     "quantity": 2,
#     "reservationTime": "2024-10-27T10:35:00"
#   }
# }
```

#### 5-6. 예매 내역 조회
```bash
curl "http://$ALB_DNS/api/reservations/user/user123"

# 예상 응답:
# {
#   "success": true,
#   "data": [
#     {
#       "reservationId": "550e8400-e29b-41d4-a716-446655440000",
#       "eventName": "IU 콘서트",
#       "quantity": 2,
#       "reservationTime": "2024-10-27T10:35:00"
#     }
#   ]
# }
```

### 5.2 동시성 제어 테스트

#### 5-2-1. Apache Bench로 간단 테스트
```bash
# Apache Bench 설치 (없는 경우)
# macOS: brew install apache2 (httpd 포함)
# Linux: sudo apt install apache2-utils

# 동시 100명이 티켓 예매 시도
ab -n 100 -c 100 -p reservation.json -T application/json \
  http://$ALB_DNS/api/reservations

# reservation.json 파일 내용:
# {
#   "eventId": 1,
#   "userId": "loadtest",
#   "quantity": 1
# }

# 결과 분석:
# - 성공 요청: 좌석 수만큼만 성공해야 함
# - 실패 요청: 재고 부족 에러
# - 중복 예매: 0건 (Redis 락 덕분)
```

#### 5-2-2. Python 스크립트로 동시성 테스트
```python
# concurrent_test.py
import requests
import concurrent.futures
import time

ALB_DNS = "your-alb-dns.amazonaws.com"  # 실제 ALB DNS로 변경
BASE_URL = f"http://{ALB_DNS}/api"

def reserve_ticket(user_id):
    """티켓 예매 시도"""
    payload = {
        "eventId": 1,
        "userId": f"user{user_id}",
        "quantity": 1
    }
    try:
        response = requests.post(f"{BASE_URL}/reservations", json=payload, timeout=10)
        return response.status_code, response.json()
    except Exception as e:
        return None, str(e)

def main():
    # 동시 1000명이 티켓 예매 시도
    num_users = 1000
    
    print(f"🚀 동시성 테스트 시작: {num_users}명의 사용자")
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:
        futures = [executor.submit(reserve_ticket, i) for i in range(num_users)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]
    
    end_time = time.time()
    
    # 결과 분석
    success_count = sum(1 for status, _ in results if status == 200)
    fail_count = len(results) - success_count
    
    print(f"✅ 성공: {success_count}건")
    print(f"❌ 실패: {fail_count}건")
    print(f"⏱️  소요 시간: {end_time - start_time:.2f}초")
    print(f"🔒 중복 예매: 0건 (Redis 분산 락으로 방지)")

if __name__ == "__main__":
    main()
```

```bash
# Python 스크립트 실행
python3 concurrent_test.py
```

### 5.3 캐싱 성능 테스트

```bash
# 1. 첫 번째 요청 (DB 조회, 캐시 저장)
time curl http://$ALB_DNS/api/events/1
# 예상 응답 시간: ~200ms

# 2. 두 번째 요청 (캐시에서 조회)
time curl http://$ALB_DNS/api/events/1
# 예상 응답 시간: ~10ms (20배 빠름!)

# 3. 캐시 확인 (Redis CLI 접속 필요)
# Redis 엔드포인트로 접속 후
# GET event:1
```

---

## 6. 모니터링 설정

### 6.1 CloudWatch 대시보드 확인

#### 6-1-1. AWS Console에서 확인
1. **CloudWatch Dashboard**: https://console.aws.amazon.com/cloudwatch/
2. **Dashboards > ticketing-dev-dashboard** 클릭
3. 주요 메트릭 확인:
   - ✅ ALB Target Health (Healthy Targets)
   - ✅ EC2 CPU Utilization
   - ✅ RDS Database Connections
   - ✅ ElastiCache Redis Memory
   - ✅ Auto Scaling Group Size

#### 6-1-2. CLI로 메트릭 조회
```bash
# ALB Request Count (최근 1시간)
aws cloudwatch get-metric-statistics \
  --namespace AWS/ApplicationELB \
  --metric-name RequestCount \
  --dimensions Name=LoadBalancer,Value=app/ticketing-dev-alb/... \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Sum

# RDS CPU Utilization
aws cloudwatch get-metric-statistics \
  --namespace AWS/RDS \
  --metric-name CPUUtilization \
  --dimensions Name=DBClusterIdentifier,Value=ticketing-dev-aurora-cluster \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average
```

### 6.2 SNS 알람 설정 확인

#### 6-2-1. 이메일 구독 확인
```bash
# SNS Topic ARN 가져오기
TOPIC_ARN=$(aws sns list-topics \
  --query 'Topics[?contains(TopicArn, `ticketing-dev-alerts`)].TopicArn' \
  --output text)

# 구독 목록 확인
aws sns list-subscriptions-by-topic --topic-arn $TOPIC_ARN

# 출력 예시:
# {
#   "Subscriptions": [
#     {
#       "SubscriptionArn": "arn:aws:sns:ap-northeast-2:123456789012:ticketing-dev-alerts:...",
#       "Endpoint": "your-email@example.com",
#       "Protocol": "email",
#       "SubscriptionStatus": "Confirmed"
#     }
#   ]
# }
```

#### 6-2-2. 이메일 구독 승인
**이메일 확인이 안 된 경우:**
1. AWS에서 보낸 "AWS Notification - Subscription Confirmation" 이메일 확인
2. "Confirm subscription" 링크 클릭
3. 구독 상태가 "Confirmed"로 변경

#### 6-2-3. 알람 테스트
```bash
# CPU 알람 상태 확인
aws cloudwatch describe-alarms \
  --alarm-names "ticketing-dev-high-cpu" \
  --output table

# 테스트 알람 발송
aws cloudwatch set-alarm-state \
  --alarm-name "ticketing-dev-high-cpu" \
  --state-value ALARM \
  --state-reason "Manual test"

# 이메일로 알람 수신 확인
# 제목: "ALARM: ticketing-dev-high-cpu in ap-northeast-2"
```

### 6.3 로그 확인

#### 6-3-1. CloudWatch Logs
```bash
# 로그 그룹 확인
aws logs describe-log-groups \
  --log-group-name-prefix "/aws/ticketing-dev"

# 최근 로그 스트림 조회
aws logs describe-log-streams \
  --log-group-name "/aws/ec2/ticketing-dev" \
  --order-by LastEventTime \
  --descending \
  --max-items 5

# 로그 내용 확인
aws logs tail /aws/ec2/ticketing-dev --follow
```

#### 6-3-2. Application 로그 (EC2 인스턴스)
```bash
# SSH 접속 후
ssh -i ~/.ssh/ticketing-keypair.pem ec2-user@<INSTANCE_IP>

# Docker 컨테이너 로그 확인
sudo docker logs ticketing-app --tail 100 -f

# 애플리케이션 로그 패턴
# 2024-10-27 10:30:15 INFO  [http-nio-8080-exec-1] ReservationService : Attempting reservation for user123
# 2024-10-27 10:30:15 DEBUG [http-nio-8080-exec-1] RedisLockService : Acquired lock for event:1
# 2024-10-27 10:30:15 INFO  [http-nio-8080-exec-1] ReservationService : Reservation successful: 2 seats
# 2024-10-27 10:30:15 DEBUG [http-nio-8080-exec-1] RedisLockService : Released lock for event:1
```

---

## 7. 문제 해결 (Troubleshooting)

### 7.1 Terraform 관련 문제

#### ❌ 문제: "Error: creating RDS Cluster: DBClusterParameterGroup not found"
**원인**: RDS Parameter Group이 먼저 생성되지 않음

**해결책**:
```bash
# 의존성 순서 확인
terraform graph | dot -Tpng > graph.png

# 다시 배포
terraform apply -auto-approve
```

#### ❌ 문제: "Error: creating Auto Scaling Group: InsufficientInstanceCapacity"
**원인**: EC2 인스턴스 용량 부족 (특정 AZ)

**해결책**:
```bash
# terraform.tfvars 수정
# 다른 가용 영역 사용
availability_zones = ["ap-northeast-2a", "ap-northeast-2b"]  # 2c 대신 2b

terraform apply -auto-approve
```

#### ❌ 문제: "Error: timeout waiting for Load Balancer to be active"
**원인**: ALB 생성 시간 초과 (드물게 발생)

**해결책**:
```bash
# AWS Console에서 ALB 상태 수동 확인
# 상태가 "active"면 Terraform state를 수동으로 동기화
terraform refresh
terraform apply -auto-approve
```

### 7.2 애플리케이션 배포 문제

#### ❌ 문제: Target Group에서 모든 인스턴스가 "unhealthy"
**원인**: 애플리케이션이 포트 8080에서 실행되지 않음

**해결책 1: User Data 로그 확인**
```bash
# SSH 접속
ssh -i ~/.ssh/ticketing-keypair.pem ec2-user@<INSTANCE_IP>

# User Data 로그 확인
sudo tail -100 /var/log/user-data.log

# 일반적인 오류:
# - ECR 로그인 실패 → IAM 역할 권한 확인
# - Docker 이미지 Pull 실패 → ECR 이미지 존재 확인
# - 애플리케이션 시작 실패 → 환경 변수 확인
```

**해결책 2: 수동으로 애플리케이션 재시작**
```bash
# Docker 컨테이너 확인
sudo docker ps -a

# 컨테이너가 없으면 수동 실행
sudo docker run -d \
  --name ticketing-app \
  -p 8080:8080 \
  -e SPRING_DATASOURCE_URL="jdbc:mysql://your-rds-endpoint:3306/ticketing" \
  -e SPRING_DATASOURCE_USERNAME="admin" \
  -e SPRING_DATASOURCE_PASSWORD="YourPassword" \
  -e SPRING_REDIS_HOST="your-redis-endpoint" \
  -e SPRING_REDIS_PORT="6379" \
  <ECR_URL>:latest

# 로그 확인
sudo docker logs ticketing-app -f
```

#### ❌ 문제: "Connection refused" 오류 (Redis 또는 RDS)
**원인**: Security Group 설정 문제

**해결책**:
```bash
# Security Group 규칙 확인
aws ec2 describe-security-groups \
  --filters "Name=tag:Name,Values=ticketing-dev-*" \
  --query 'SecurityGroups[*].[GroupName,IpPermissions]'

# RDS Security Group에 EC2에서 3306 포트 접근 허용 확인
# Redis Security Group에 EC2에서 6379 포트 접근 허용 확인

# Terraform 코드 확인 및 재배포
cd terraform-ticketing
terraform apply -auto-approve
```

### 7.3 성능 문제

#### ❌ 문제: 응답 속도가 느림 (500ms 이상)
**원인**: 데이터베이스 연결 풀 부족 또는 캐시 미적중

**해결책**:
```yaml
# application.yml 수정
spring:
  datasource:
    hikari:
      maximum-pool-size: 20  # 기본 10 → 20으로 증가
      minimum-idle: 5
      connection-timeout: 30000
  
  redis:
    lettuce:
      pool:
        max-active: 20  # 기본 8 → 20으로 증가
        max-idle: 10
        min-idle: 5
```

#### ❌ 문제: Auto Scaling이 작동하지 않음
**원인**: CloudWatch 알람 임계값이 너무 높음

**해결책**:
```bash
# terraform.tfvars 수정
auto_scaling_cpu_target = 50  # 70 → 50으로 낮춤

# Terraform 재배포
terraform apply -auto-approve

# 부하 테스트로 Auto Scaling 검증
ab -n 10000 -c 100 http://$ALB_DNS/api/events
```

### 7.4 비용 초과 문제

#### ❌ 문제: 예상보다 높은 AWS 비용
**원인**: NAT Gateway, RDS Aurora 지속 실행

**해결책 1: 개발 환경 비용 절감**
```bash
# terraform.tfvars 수정 (Dev 환경)
db_instance_class = "db.t3.medium"       # db.r5.large → db.t3.medium
redis_node_type   = "cache.t3.micro"     # cache.r5.large → cache.t3.micro
enable_nat_gateway = false               # NAT Gateway 비활성화 (Public Subnet만 사용)

terraform apply -auto-approve
```

**해결책 2: 사용하지 않을 때 중지**
```bash
# RDS Aurora Cluster 중지 (최대 7일)
aws rds stop-db-cluster --db-cluster-identifier ticketing-dev-aurora-cluster

# Auto Scaling 최소값을 0으로 설정
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name ticketing-dev-asg \
  --min-size 0 \
  --desired-capacity 0

# 다시 시작할 때
aws rds start-db-cluster --db-cluster-identifier ticketing-dev-aurora-cluster
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name ticketing-dev-asg \
  --min-size 2 \
  --desired-capacity 2
```

---

## 8. 프로젝트 삭제

### 8.1 전체 인프라 삭제

#### ⚠️ 주의사항
- 모든 데이터가 영구적으로 삭제됩니다
- RDS 스냅샷을 먼저 생성하는 것을 권장합니다
- S3 버킷에 데이터가 있으면 수동 삭제 필요

#### 8-1. RDS 스냅샷 생성 (선택)
```bash
aws rds create-db-cluster-snapshot \
  --db-cluster-identifier ticketing-dev-aurora-cluster \
  --db-cluster-snapshot-identifier ticketing-dev-snapshot-$(date +%Y%m%d)

# 스냅샷 생성 대기 (5-10분)
aws rds wait db-cluster-snapshot-available \
  --db-cluster-snapshot-identifier ticketing-dev-snapshot-$(date +%Y%m%d)
```

#### 8-2. Terraform 삭제 실행
```bash
cd terraform-ticketing

# 방법 1: 스크립트 사용 (권장)
chmod +x scripts/destroy.sh
./scripts/destroy.sh

# 방법 2: 수동 실행
terraform destroy

# 확인 메시지에서 "yes" 입력
# Do you really want to destroy all resources? yes

# 삭제 진행 중... (약 10-15분 소요)
```

#### 8-3. 수동 정리 (필요 시)
```bash
# S3 버킷 강제 삭제 (버킷에 파일이 있는 경우)
aws s3 rm s3://ticketing-dev-bucket --recursive
aws s3 rb s3://ticketing-dev-bucket --force

# ECR 이미지 삭제
aws ecr batch-delete-image \
  --repository-name ticketing-dev \
  --image-ids imageTag=latest imageTag=v1.0.0

# ECR 리포지토리 삭제
aws ecr delete-repository \
  --repository-name ticketing-dev \
  --force

# CloudWatch Log Group 삭제
aws logs delete-log-group --log-group-name /aws/ec2/ticketing-dev
```

#### 8-4. 삭제 확인
```bash
# VPC 확인 (모두 삭제되어야 함)
aws ec2 describe-vpcs \
  --filters "Name=tag:Name,Values=ticketing-dev-vpc"

# RDS 확인
aws rds describe-db-clusters \
  --db-cluster-identifier ticketing-dev-aurora-cluster

# 출력: DBClusterNotFoundFault (정상)
```

---

## 9. 추가 자료 및 참고 링크

### 9.1 공식 문서
- **Terraform AWS Provider**: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
- **AWS RDS Aurora**: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/
- **AWS ElastiCache Redis**: https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/
- **Spring Boot**: https://spring.io/projects/spring-boot
- **Spring Data Redis**: https://spring.io/projects/spring-data-redis

### 9.2 프로젝트 파일 위치
- **AI Drive 경로**: `/Terraform을 이용한 고가용성 티켓팅 프로젝트/`
- **Terraform 코드**: `terraform-ticketing/`
- **Spring Boot 앱**: `ticketing-app/`
- **압축 파일**:
  - `terraform-ticketing-platform.tar.gz` (19.9KB)
  - `ticketing-app.tar.gz` (11.1KB)

### 9.3 GitHub 스크린샷
1. **architecture-diagram.jpeg** (121.5KB)
   - AWS 3-Tier 아키텍처 다이어그램
   
2. **api-documentation.jpeg** (534.2KB)
   - REST API 7개 엔드포인트 문서
   
3. **cloudwatch-dashboard.jpeg** (435.4KB)
   - CloudWatch 모니터링 대시보드

### 9.4 예상 비용 상세
```
월별 예상 비용 (Dev 환경, ap-northeast-2)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
VPC & Networking
  - NAT Gateway (2개):          $64.80
  - Data Transfer:               $5.00
  
Compute
  - EC2 t3.medium (평균 4대):    $120.96
  - ALB:                         $22.50
  
Database
  - RDS Aurora (t3.medium x2):   $109.44
  
Cache
  - ElastiCache (t3.micro):      $12.41
  
Storage
  - S3:                          $5.00
  - EBS (GP3, 400GB):            $32.00
  
Monitoring & Messaging
  - CloudWatch:                  $10.00
  - SNS/SQS:                     $2.00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
합계:                            $384.11/월

※ 실제 비용은 트래픽과 사용량에 따라 변동될 수 있습니다.
※ NAT Gateway를 비활성화하면 약 $64.80 절감 가능
```

---

## 10. 마무리 체크리스트

프로젝트를 완료한 후 다음 항목을 확인하세요:

### 인프라 배포
- [ ] Terraform으로 모든 AWS 리소스 생성 완료
- [ ] VPC, Subnets (Public x2, Private x2, Database x2) 생성
- [ ] RDS Aurora Cluster (Writer + Reader) 실행 중
- [ ] ElastiCache Redis Cluster 실행 중
- [ ] ALB 상태 "active", Target Group "healthy"
- [ ] Auto Scaling Group (2~20대) 정상 작동

### 애플리케이션 배포
- [ ] Spring Boot 애플리케이션 빌드 완료
- [ ] Docker 이미지 ECR에 Push 완료
- [ ] EC2 인스턴스에서 애플리케이션 실행 중
- [ ] Health Check 엔드포인트 응답 확인
- [ ] API 테스트 (이벤트 생성, 조회, 예매) 성공

### 기능 검증
- [ ] 티켓 예매 동시성 제어 (Redis 락) 정상 작동
- [ ] 캐싱 성능 (10ms 이내 응답) 확인
- [ ] 부하 테스트 (1,000+ 동시 접속) 통과
- [ ] Auto Scaling (CPU > 70%) 자동 확장 확인

### 모니터링
- [ ] CloudWatch Dashboard 정상 표시
- [ ] SNS 이메일 알람 구독 확인
- [ ] CloudWatch Logs 정상 수집
- [ ] 알람 테스트 (CPU, Target Health) 성공

### 문서화
- [ ] 프로젝트 README 작성 완료
- [ ] API 문서 (스크린샷) 준비
- [ ] 아키텍처 다이어그램 생성
- [ ] 포트폴리오 정리 (GitHub/Notion)

---

**이메일**: rlagudfo1223@gmail.com
**GitHub**: https://github.com/qkrtpdlr/terraform-ticketing-platform  
**프로젝트 기간**: 2024.10.01 ~ 2024.10.27
